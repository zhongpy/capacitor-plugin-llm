{"version":3,"file":"definitions.js","sourceRoot":"","sources":["../../src/definitions.ts"],"names":[],"mappings":"","sourcesContent":["// definitions.ts\nexport type LLMTokenEvent = { token: string };\nexport type LLMDoneEvent = Record<string, never>;\nexport type LLMErrorEvent = { message: string };\n\nexport interface InitOptions {\n  assetPath?: string;\n  expectedSha256?: string;\n  modelPath?: string;\n  remoteUrl?: string;\n  nCtx?: number;\n}\n\nexport interface ChatOptions {\n  prompt: string; // 会包 ChatML\n}\n\nexport interface GenerateEssayOptions {\n  title?: string;\n  word_limit?: number;\n  lang?: string;\n  constraints?: {\n    high_error_words?: string[];\n    high_freq_words?: string[];\n  };\n  max_new_tokens?: number;\n}\n\nexport interface SetSamplingOptions {\n  temp?: number; // 默认 0.8\n  topP?: number; // 默认 0.95\n  topK?: number; // 默认 40\n  repeatPenalty?: number; // 默认 1.10\n  repeatLastN?: number; // 默认 256\n  minP?: number; // 默认 0.05\n}\n\nexport interface PluginListenerHandle {\n  remove: () => Promise<void>;\n}\n\nexport interface LLMPlugin {\n  init(options: InitOptions): Promise<void>;\n  chat(options: ChatOptions): Promise<void>;\n  stop(): Promise<void>;\n  free(): Promise<void>;\n  generateEssay(options: GenerateEssayOptions): Promise<{ text: string }>;\n  /** 新增：动态调采样参数（映射到 nativeSetSampling） */\n  setSampling(options: SetSamplingOptions): Promise<void>;\n\n  addListener(eventName: 'llmToken', listenerFunc: (event: LLMTokenEvent) => void): Promise<PluginListenerHandle>;\n  addListener(eventName: 'llmDone', listenerFunc: (event: LLMDoneEvent) => void): Promise<PluginListenerHandle>;\n  addListener(eventName: 'llmError', listenerFunc: (event: LLMErrorEvent) => void): Promise<PluginListenerHandle>;\n}\n"]}