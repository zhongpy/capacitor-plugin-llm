{"version":3,"file":"definitions.js","sourceRoot":"","sources":["../../src/definitions.ts"],"names":[],"mappings":"","sourcesContent":["export type LLMTokenEvent = { token: string };\nexport type LLMDoneEvent  = Record<string, never>;\nexport type LLMErrorEvent = { message: string };\n\nexport interface InitOptions {\n  /** 优先从 assets 复制（例：models/Qwen3-0.6B-Instruct-q4_k_m.gguf） */\n  assetPath?: string;\n  /** 可选的 SHA256 校验（hex 小写/大写都可） */\n  expectedSha256?: string;\n  /** 已存在的绝对路径（若提供优先生效） */\n  modelPath?: string;\n  /** 本地没有则从该 URL 下载到 filesDir/models/ */\n  remoteUrl?: string;\n  /** 上下文长度（默认 1024） */\n  nCtx?: number;\n}\n\nexport interface ChatOptions {\n  /** 用户提示词（会包上 ChatML 模板） */\n  prompt: string;\n}\n\nexport interface GenerateEssayOptions {\n  /** 作文标题 */\n  title?: string;\n  /** 目标字数（近似） */\n  word_limit?: number;\n  /** 语言（默认 en） */\n  lang?: string;\n  /** 约束条件 */\n  constraints?: {\n    /** 高错误率词 */\n    high_error_words?: string[];\n    /** 高频词 */\n    high_freq_words?: string[];\n  };\n  /** 最大新生成 tokens（默认 max(256, word_limit*3)） */\n  max_new_tokens?: number;\n}\n\nexport interface LLMPlugin {\n  /** 初始化（复制/下载模型 + nativeInit） */\n  init(options: InitOptions): Promise<void>;\n\n  /** 开始流式对话（逐 token 触发 llmToken，结束触发 llmDone） */\n  chat(options: ChatOptions): Promise<void>;\n\n  /** 尝试中断当前流式生成 */\n  stop(): Promise<void>;\n\n  /** 释放底层资源（模型/上下文） */\n  free(): Promise<void>;\n\n  /** 一次性生成（作文） */\n  generateEssay(options: GenerateEssayOptions): Promise<{ text: string }>;\n\n  // Events\n  addListener(eventName: 'llmToken', listenerFunc: (event: LLMTokenEvent) => void): Promise<PluginListenerHandle>;\n  addListener(eventName: 'llmDone',  listenerFunc: (event: LLMDoneEvent)  => void): Promise<PluginListenerHandle>;\n  addListener(eventName: 'llmError', listenerFunc: (event: LLMErrorEvent) => void): Promise<PluginListenerHandle>;\n}\n\nexport interface PluginListenerHandle {\n  remove: () => Promise<void>;\n}\n"]}