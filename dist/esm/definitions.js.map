{"version":3,"file":"definitions.js","sourceRoot":"","sources":["../../src/definitions.ts"],"names":[],"mappings":"","sourcesContent":["// definitions.ts\r\nexport type LLMTokenEvent = { token: string };\r\nexport type LLMDoneEvent = Record<string, never>;\r\nexport type LLMErrorEvent = { message: string };\r\n\r\nexport interface InitOptions {\r\n  assetPath?: string;\r\n  expectedSha256?: string;\r\n  modelPath?: string;\r\n  remoteUrl?: string;\r\n  nCtx?: number;\r\n}\r\n\r\nexport interface ChatOptions {\r\n  prompt: string; // 会包 ChatML\r\n}\r\n\r\nexport interface GenerateEssayOptions {\r\n  title?: string;\r\n  word_limit?: number;\r\n  lang?: string;\r\n  constraints?: {\r\n    high_error_words?: string[];\r\n    high_freq_words?: string[];\r\n  };\r\n  max_new_tokens?: number;\r\n}\r\n\r\nexport interface SetSamplingOptions {\r\n  temp?: number; // 默认 0.8\r\n  topP?: number; // 默认 0.95\r\n  topK?: number; // 默认 40\r\n  repeatPenalty?: number; // 默认 1.10\r\n  repeatLastN?: number; // 默认 256\r\n  minP?: number; // 默认 0.05\r\n}\r\n\r\nexport interface PluginListenerHandle {\r\n  remove: () => Promise<void>;\r\n}\r\n\r\nexport interface LLMPlugin {\r\n  init(options: InitOptions): Promise<void>;\r\n  chat(options: ChatOptions): Promise<void>;\r\n  stop(): Promise<void>;\r\n  free(): Promise<void>;\r\n  generateEssay(options: GenerateEssayOptions): Promise<{ text: string }>;\r\n  /** 新增：动态调采样参数（映射到 nativeSetSampling） */\r\n  setSampling(options: SetSamplingOptions): Promise<void>;\r\n\r\n  addListener(eventName: 'llmToken', listenerFunc: (event: LLMTokenEvent) => void): Promise<PluginListenerHandle>;\r\n  addListener(eventName: 'llmDone', listenerFunc: (event: LLMDoneEvent) => void): Promise<PluginListenerHandle>;\r\n  addListener(eventName: 'llmError', listenerFunc: (event: LLMErrorEvent) => void): Promise<PluginListenerHandle>;\r\n}\r\n"]}